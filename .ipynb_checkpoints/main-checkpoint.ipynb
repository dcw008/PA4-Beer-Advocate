{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n",
      "6\n",
      "[[[1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 0, 1], [1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0]], [[1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from models import *\n",
    "# from config import cfg\n",
    "import pandas as pd\n",
    "from nltk.translate import bleu_score\n",
    "import pickle\n",
    "\n",
    "\n",
    "def saveVocabulary(vocabulary):\n",
    "    #note loaders are saved already\n",
    "    data = {}\n",
    "    data['vocabulary'] = vocabulary\n",
    "    print(\"start saving vocabulary to pickle\")\n",
    "    with open('vocabulary.pickle','wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL) \n",
    "        print(\"finished writing to pickle\")\n",
    "\n",
    "def getVocabulary():\n",
    "    with open('vocabulary.pickle','rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "    return data['vocabulary']\n",
    "\n",
    "\n",
    "VOCABULARY = getVocabulary()\n",
    "VOCABULARY_FLIP = dict((v,k) for k,v in VOCABULARY.items()) \n",
    "\n",
    "def char2oh(c):\n",
    "    oh = [0] * len(VOCABULARY)\n",
    "    c_index = VOCABULARY[c] if c in VOCABULARY else VOCABULARY['< UNK >']\n",
    "    oh[c_index] = 1\n",
    "    return oh\n",
    "\n",
    "def oh2char(oh):\n",
    "    if len(oh) > len(VOCABULARY_FLIP):\n",
    "        return None\n",
    "    for index, e in enumerate(oh):\n",
    "        if e == 1:\n",
    "            return VOCABULARY_FLIP[index]\n",
    "    return None\n",
    "    \n",
    "\n",
    "def load_data(fname):\n",
    "    # TODO: From the csv file given by filename and return a pandas DataFrame of the read csv.\n",
    "    return pd.read_csv(fname)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The data should be per mini-batch basis, https://piazza.com/class/jml6wogpji0o3?cid=450\n",
    "def process_train_data(data):\n",
    "    # TODO: Input is a pandas DataFrame and return a numpy array (or a torch Tensor/ Variable)\n",
    "    # that has all features (including characters in one hot encoded form).\n",
    "    \n",
    "    #pre-assign all the possible beer styles\n",
    "    beer_style_array = ['Old Ale', 'Bière de Champagne / Bière Brut', 'American Amber / Red Ale', 'Oatmeal Stout', 'Belgian Dark Ale', 'Schwarzbier', 'Witbier', 'Weizenbock', 'English Brown Ale', 'Irish Dry Stout', 'Fruit / Vegetable Beer', 'Japanese Rice Lager', 'English Dark Mild Ale', 'Maibock / Helles Bock', 'Czech Pilsener', 'German Pilsener', 'American Pale Ale (APA)', 'Rauchbier', 'American Malt Liquor', 'American Amber / Red Lager', 'American Pale Wheat Ale', 'Märzen / Oktoberfest', 'English Porter', 'Euro Pale Lager', 'Scotch Ale / Wee Heavy', 'American Stout', 'Belgian Strong Pale Ale', 'American Brown Ale', 'Pumpkin Ale', 'Lambic - Fruit', 'Altbier', 'Bière de Garde', 'Lambic - Unblended', 'English Strong Ale', 'Sahti', 'Eisbock', 'Dortmunder / Export Lager', 'English Pale Ale', 'Gose', 'Kölsch', 'American Dark Wheat Ale', 'Berliner Weissbier', 'Euro Strong Lager', 'Low Alcohol Beer', 'English Stout', 'Rye Beer', 'American IPA', 'Happoshu', 'American Blonde Ale', 'American Adjunct Lager', 'American Black Ale', 'Black & Tan', 'California Common / Steam Beer', 'Munich Dunkel Lager', 'Munich Helles Lager', 'English Barleywine', 'Kristalweizen', 'Vienna Lager', 'Wheatwine', 'English India Pale Ale (IPA)', 'Braggot', 'Smoked Beer', 'Doppelbock', 'Milk / Sweet Stout', 'Scottish Ale', 'Cream Ale', 'Belgian Strong Dark Ale', 'Scottish Gruit / Ancient Herbed Ale', 'Faro', 'Hefeweizen', 'Dunkelweizen', 'Russian Imperial Stout', 'American Porter', 'American Strong Ale', 'Gueuze', 'Euro Dark Lager', 'Roggenbier', 'Keller Bier / Zwickel Bier', 'Extra Special / Strong Bitter (ESB)', 'American Double / Imperial Stout', 'Irish Red Ale', 'Foreign / Export Stout', 'Belgian IPA', 'English Bitter', 'English Pale Mild Ale', 'American Pale Lager', 'Baltic Porter', 'Kvass', 'Light Lager', 'Tripel', 'Flanders Red Ale', 'American Wild Ale', 'Saison / Farmhouse Ale', 'Belgian Pale Ale', 'American Double / Imperial Pilsner', 'Dubbel', 'American Double / Imperial IPA', 'Bock', 'Chile Beer', 'Herbed / Spiced Beer', 'Flanders Oud Bruin', 'Winter Warmer', 'Quadrupel (Quad)', 'American Barleywine']\n",
    "    beer_style_record = {k: v for v, k in enumerate(beer_style_array)} # {'Old Ale': 0, 'Bière de Champagne / Bière Brut', 1 ...}\n",
    "    \n",
    "    # key is the vocabulary, value is the index\n",
    "    # load from pickle\n",
    "  \n",
    "    \n",
    "    \n",
    "    # save the vocabulary\n",
    "    \"\"\"\n",
    "    # save the vocabulary to pickle\n",
    "    vocabularySet = set()\n",
    "    vocabularySet.add('< SOS >')\n",
    "    vocabularySet.add('< EOS >')\n",
    "    vocabularySet.add('< UNK >')\n",
    "    for index, row in data.iterrows():\n",
    "        review_text = list((str(row['review/text'])))\n",
    "        for c in review_text:\n",
    "            vocabularySet.add(c)\n",
    "    vocabulary_record = {k: v for v, k in enumerate(vocabularySet)}\n",
    "    saveVocabulary(vocabulary_record)\n",
    "    \"\"\"\n",
    "    \n",
    "    # inputs: N × m × d, N is the number of reviews, m is the number of characters in each review text, \n",
    "    # d is the dimension of the concatenation of metadata feature vector and one hot encoded representation\n",
    "    inputs = []\n",
    "    for index, row in data.iterrows():\n",
    "        beer_style, review_overall, review_text = row['beer/style'], row['review/overall'], list((str(row['review/text'])))\n",
    "        review_text.insert(0, '< SOS >')\n",
    "        review_text.append('< EOS >')\n",
    "        beer_style_one_hot = [0] * len(beer_style_array)\n",
    "        review_overall_one_hot = [0] * 9 # rating from 1, 1.5, ... 4.5, 5\n",
    "        if beer_style in beer_style_record:\n",
    "            beer_style_one_hot[beer_style_record[beer_style]] = 1\n",
    "            review_overall_one_hot[int(review_overall / 0.5 - 2)]  = 1\n",
    "        else:\n",
    "            continue\n",
    "        meta_data_feature_vector_one_hot = review_overall_one_hot + beer_style_one_hot\n",
    "        c_inputs = []\n",
    "        for c in review_text:\n",
    "            c_index = vocabulary[c] if c in vocabulary else vocabulary['< UNK >']\n",
    "            review_text_character_one_hot = [0] * len(vocabulary)\n",
    "            review_text_character_one_hot[c_index] = 1\n",
    "            # concatenate the review_overall_one_hot and beer_style_one_hot\n",
    "            concat = meta_data_feature_vector_one_hot + review_text_character_one_hot\n",
    "            c_inputs.append(concat)\n",
    "        inputs.append(c_inputs)\n",
    "        # TODO: remove when it's ready to train the model\n",
    "        if index == 100:\n",
    "            break\n",
    "    return inputs\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "def train_valid_split(data, labels):\n",
    "    # TODO: Takes in train data and labels as numpy array (or a torch Tensor/ Variable) and\n",
    "    # splits it into training and validation data.\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    \n",
    "def process_test_data(data):\n",
    "    # TODO: Takes in pandas DataFrame and returns a numpy array (or a torch Tensor/ Variable)\n",
    "    # that has all input features. Note that test data does not contain any review so you don't\n",
    "    # have to worry about one hot encoding the data.\n",
    "    raise NotImplementedError\n",
    "\n",
    "    \n",
    "def pad_data(orig_data):\n",
    "    # TODO: Since you will be training in batches and training sample of each batch may have reviews\n",
    "    # of varying lengths, you will need to pad your data so that all samples have reviews of length\n",
    "    # equal to the longest review in a batch. You will pad all the sequences with <EOS> character \n",
    "    # representation in one hot encoding.\n",
    "    \n",
    "    # each element in the orig_data should be a list of one-hot encoding for each sample in this given mini-batch\n",
    "    \"\"\"\n",
    "    orig_data : \n",
    "    [\n",
    "     ['oh(< SOS >)', 'oh(a)', 'oh(b)', 'oh(c)', 'oh< EOS >'],  # review 1\n",
    "     ['oh(< SOS >)', 'oh(h)', 'oh(e)', 'oh(l)', 'oh(l)', 'oh(o)','oh< EOS >']  # review 2\n",
    "     ['oh(< SOS >)', 'oh(y)', 'oh(e)', 'oh< EOS >']  # review 3\n",
    "    ]\n",
    "    \"\"\" \n",
    "    max_len = max([len(element) for element in orig_data])\n",
    "    # pad each review to the same length as max_len\n",
    "    for element in orig_data:\n",
    "        l = len(element)\n",
    "        if l < max_len:\n",
    "            # need to pad this element\n",
    "            eos_oh = char2oh('< EOS >')\n",
    "            eos_to_pad = [eos_oh] * (max_len - l)\n",
    "            element += eos_to_pad\n",
    "    return orig_data\n",
    "    \n",
    "\n",
    "def train(model, X_train, y_train, X_valid, y_valid, cfg):\n",
    "    # TODO: Train the model!\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    \n",
    "def generate(model, X_test, cfg):\n",
    "    # TODO: Given n rows in test data, generate a list of n strings, where each string is the review\n",
    "    # corresponding to each input row in test data.\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    \n",
    "def save_to_file(outputs, fname):\n",
    "    # TODO: Given the list of generated review outputs and output file name, save all these reviews to\n",
    "    # the file in .txt format.\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_data_fname = \"Beeradvocate_Train.csv\"\n",
    "    test_data_fname = \"Beeradvocate_Test.csv\"\n",
    "    out_fname = \"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    train_data = load_data(train_data_fname) # Generating the pandas DataFrame\n",
    "    test_data = load_data(test_data_fname) # Generating the pandas DataFrame\n",
    "    process_train_data(train_data) # Converting DataFrame to numpy array\n",
    "\n",
    "    \n",
    "#     train_data, train_labels = process_train_data(train_data) # Converting DataFrame to numpy array\n",
    "#     print(train_data)\n",
    "    \n",
    "    \n",
    "\n",
    "    X_train, y_train, X_valid, y_valid = train_valid_split(train_data, train_labels) # Splitting the train data into train-valid data\n",
    "    X_test = process_test_data(test_data) # Converting DataFrame to numpy array\n",
    "    \n",
    "    model = baselineLSTM(cfg) # Replace this with model = <your model name>(cfg)\n",
    "    if cfg['cuda']:\n",
    "        computing_device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        computing_device = torch.device(\"cpu\")\n",
    "    model.to(computing_device)\n",
    "    \n",
    "    train(model, X_train, y_train, X_valid, y_valid, cfg) # Train the model\n",
    "    outputs = generate(model, X_test, cfg) # Generate the outputs for test data\n",
    "    save_to_file(outputs, out_fname) # Save the generated outputs to a file\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
