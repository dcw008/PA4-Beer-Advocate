cfg = {}
cfg['input_dim'] = 217 # input dimension to LSTM, rating(1) + number_of_beer_style(104) + len_vocaubulary(112), 
cfg['hidden_dim'] = 112 # hidden dimension for LSTM , TODO: need to confirm, the hidden_dim equals to the len of the vocabulary
cfg['output_dim'] = 112 # output dimension of the model,  TODO: need to confirm, the output_dim equals to the len of the vocabulary
cfg['layers'] = 2 # number of layers of LSTM
cfg['dropout'] = 0.5 # dropout rate between two layers of LSTM; useful only when layers > 1; between 0 and 1
cfg['bidirectional'] = False # True or False; True means using a bidirectional LSTM
cfg['batch_size'] = 50 # batch size of input
cfg['learning_rate'] = 0.0001 # learning rate to be used
cfg['L2_penalty'] = 0.5 # weighting constant for L2 regularization term; this is a parameter when you define optimizer
cfg['gen_temp'] = 0.4 # temperature to use while generating reviews
# cfg['max_len'] = # maximum character length of the generated reviews, TODO: do we really need the max_len as we are considering the max_len to be per mini-batch basis?
cfg['epochs'] = 50 # number of epochs for which the model is trained
cfg['cuda'] = True #True or False depending whether you want to run your model on a GPU or not. If you set this to True, make sure to start a GPU pod on ieng6 server
cfg['train'] = True # True or False; True denotes that the model is bein deployed in training mode, False means the model is not being used to generate reviews