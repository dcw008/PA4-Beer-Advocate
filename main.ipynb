{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init from baselineLSTM\n",
      "cuda availabe\n",
      "22847\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from models import *\n",
    "from configs import cfg\n",
    "import pandas as pd\n",
    "from nltk.translate import bleu_score\n",
    "import pickle\n",
    "\n",
    "\n",
    "def saveVocabulary(vocabulary):\n",
    "    #note loaders are saved already\n",
    "    data = {}\n",
    "    data['vocabulary'] = vocabulary\n",
    "    print(\"start saving vocabulary to pickle\")\n",
    "    with open('vocabulary.pickle','wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL) \n",
    "        print(\"finished writing to pickle\")\n",
    "\n",
    "def getVocabulary():\n",
    "    with open('vocabulary.pickle','rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "    return data['vocabulary']\n",
    "\n",
    "\n",
    "VOCABULARY = getVocabulary()\n",
    "VOCABULARY_FLIP = dict((v,k) for k,v in VOCABULARY.items()) \n",
    "\n",
    "BEER_STYLE_ARRAY = ['Old Ale', 'Bière de Champagne / Bière Brut', 'American Amber / Red Ale', 'Oatmeal Stout', 'Belgian Dark Ale', 'Schwarzbier', 'Witbier', 'Weizenbock', 'English Brown Ale', 'Irish Dry Stout', 'Fruit / Vegetable Beer', 'Japanese Rice Lager', 'English Dark Mild Ale', 'Maibock / Helles Bock', 'Czech Pilsener', 'German Pilsener', 'American Pale Ale (APA)', 'Rauchbier', 'American Malt Liquor', 'American Amber / Red Lager', 'American Pale Wheat Ale', 'Märzen / Oktoberfest', 'English Porter', 'Euro Pale Lager', 'Scotch Ale / Wee Heavy', 'American Stout', 'Belgian Strong Pale Ale', 'American Brown Ale', 'Pumpkin Ale', 'Lambic - Fruit', 'Altbier', 'Bière de Garde', 'Lambic - Unblended', 'English Strong Ale', 'Sahti', 'Eisbock', 'Dortmunder / Export Lager', 'English Pale Ale', 'Gose', 'Kölsch', 'American Dark Wheat Ale', 'Berliner Weissbier', 'Euro Strong Lager', 'Low Alcohol Beer', 'English Stout', 'Rye Beer', 'American IPA', 'Happoshu', 'American Blonde Ale', 'American Adjunct Lager', 'American Black Ale', 'Black & Tan', 'California Common / Steam Beer', 'Munich Dunkel Lager', 'Munich Helles Lager', 'English Barleywine', 'Kristalweizen', 'Vienna Lager', 'Wheatwine', 'English India Pale Ale (IPA)', 'Braggot', 'Smoked Beer', 'Doppelbock', 'Milk / Sweet Stout', 'Scottish Ale', 'Cream Ale', 'Belgian Strong Dark Ale', 'Scottish Gruit / Ancient Herbed Ale', 'Faro', 'Hefeweizen', 'Dunkelweizen', 'Russian Imperial Stout', 'American Porter', 'American Strong Ale', 'Gueuze', 'Euro Dark Lager', 'Roggenbier', 'Keller Bier / Zwickel Bier', 'Extra Special / Strong Bitter (ESB)', 'American Double / Imperial Stout', 'Irish Red Ale', 'Foreign / Export Stout', 'Belgian IPA', 'English Bitter', 'English Pale Mild Ale', 'American Pale Lager', 'Baltic Porter', 'Kvass', 'Light Lager', 'Tripel', 'Flanders Red Ale', 'American Wild Ale', 'Saison / Farmhouse Ale', 'Belgian Pale Ale', 'American Double / Imperial Pilsner', 'Dubbel', 'American Double / Imperial IPA', 'Bock', 'Chile Beer', 'Herbed / Spiced Beer', 'Flanders Oud Bruin', 'Winter Warmer', 'Quadrupel (Quad)', 'American Barleywine']\n",
    "BEER_STYLE_RECORD = {k: v for v, k in enumerate(BEER_STYLE_ARRAY)} # {'Old Ale': 0, 'Bière de Champagne / Bière Brut', 1 ...}\n",
    "\n",
    "def char2oh(c):\n",
    "    oh = [0] * len(VOCABULARY) #use numpy array instead of list\n",
    "#     oh = np.zeros(len(VOCABULARY), 1)\n",
    "    c_index = VOCABULARY[c] if c in VOCABULARY else VOCABULARY['< UNK >']\n",
    "    oh[c_index] = 1\n",
    "    return oh\n",
    "\n",
    "def oh2char(oh):\n",
    "    if len(oh) > len(VOCABULARY_FLIP):\n",
    "        return None\n",
    "    for index, e in enumerate(oh):\n",
    "        if e == 1:\n",
    "            return VOCABULARY_FLIP[index]\n",
    "    return None\n",
    "    \n",
    "\n",
    "def load_data(fname):\n",
    "    # TODO: From the csv file given by filename and return a pandas DataFrame of the read csv.\n",
    "    return pd.read_csv(fname)\n",
    "\n",
    "# save the vocabulary\n",
    "\"\"\"\n",
    "# save the vocabulary to pickle\n",
    "vocabularySet = set()\n",
    "vocabularySet.add('< SOS >')\n",
    "vocabularySet.add('< EOS >')\n",
    "vocabularySet.add('< UNK >')\n",
    "for index, row in data.iterrows():\n",
    "    review_text = list((str(row['review/text'])))\n",
    "    for c in review_text:\n",
    "        vocabularySet.add(c)\n",
    "vocabulary_record = {k: v for v, k in enumerate(vocabularySet)}\n",
    "saveVocabulary(vocabulary_record)\n",
    "\"\"\"\n",
    "\n",
    "# The data should be per mini-batch basis, https://piazza.com/class/jml6wogpji0o3?cid=450\n",
    "def process_train_data(chunk, cfg):\n",
    "    # TODO: Input is a pandas DataFrame and return a numpy array (or a torch Tensor/ Variable)\n",
    "    # that has all features (including characters in one hot encoded form).\n",
    "    # don't perform one-hot encoding here for all the dataframe, otherwise, you will get a memory issue\n",
    "    # the one-hot encoding should be per mini-batch basis\n",
    "    \n",
    "    \"\"\"\n",
    "    Let the final input after concatenation of metadata feature vector and one hot encoded representation be\n",
    "    a d dimensional vector. In this case, your input for processed training data will be of size N × m × d,\n",
    "    and labels will be of size N × m × v, where v is the length of one hot encoded vector\n",
    "    \"\"\"\n",
    "        \n",
    "    batch_c_one_hot_list = []\n",
    "    # pad the char one hot encoding\n",
    "    for index, row in chunk.iterrows():\n",
    "        c_one_hot_list = []\n",
    "        review_text = list((str(row['review/text']))) #use cuda tensor instead list\n",
    "        review_text.insert(0, '< SOS >') #TODO use tensor.cat (same as append) instead of insert\n",
    "        review_text.append('< EOS >')#TODO use tensor.cat (same as append) instead of insert\n",
    "        #convert each review to ohc\n",
    "        for c in review_text:\n",
    "            c_one_hot = char2oh(c) # 112 *1\n",
    "            c_one_hot_list.append(c_one_hot)\n",
    "        batch_c_one_hot_list.append(c_one_hot_list) #use cuda tensor instead\n",
    "    #after getting the ohc, we have to pad to the longest review\n",
    "    batch_c_one_hot_list = pad_data(batch_c_one_hot_list) #pads all the reviews to max review length\n",
    "\n",
    "    \n",
    "    \n",
    "    batch_concat_one_hot_list = [] #holds all the ohc for the entire batch\n",
    "    batch_label_one_hot_list = [] #same as above but shifted\n",
    "    \n",
    "    #concat style and rating\n",
    "    for index, row in chunk.iterrows():\n",
    "        beer_style, review_overall = row['beer/style'], row['review/overall']\n",
    "        concat_one_hot_list = [] #store the FULL ohc for one review\n",
    "        label_one_hot_list = []  #same as above but shifted the right\n",
    "        # Meta feature vector should be fixed per review\n",
    "        beer_style_one_hot = [0] * len(BEER_STYLE_ARRAY) #change this to np zeros\n",
    "        if beer_style in BEER_STYLE_RECORD:\n",
    "            beer_style_one_hot[BEER_STYLE_RECORD[beer_style]] = 1\n",
    "            review_overall_one_hot = [review_overall] #review overall is a score 1-5. need to change to cuda tensor\n",
    "            meta_data_feature_vector_one_hot = review_overall_one_hot + beer_style_one_hot #cuda cat\n",
    "            # generate the concatenated one hot representation\n",
    "            #iterate over the one hot encoded reviews from before\n",
    "            for c_one_hot in batch_c_one_hot_list[index%cfg['batch_size']]: \n",
    "                #TODO use cuda\n",
    "                concat_one_hot = c_one_hot + meta_data_feature_vector_one_hot # dimension 217(with concatenation), input, current char. \n",
    "                concat_one_hot_list.append(concat_one_hot) #use cuda\n",
    "                # dimension 112, lable/output, next char\n",
    "                label_one_hot_list.append(c_one_hot)\n",
    "            batch_concat_one_hot_list.append(concat_one_hot_list)\n",
    "            # label\n",
    "            #TODO fix runtime for this\n",
    "            label_one_hot_list = label_one_hot_list[1:] + [char2oh('< EOS >')] # shift 1 element to point to next char\n",
    "            batch_label_one_hot_list.append(label_one_hot_list)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    \"\"\" DEBUG PRINT\n",
    "    print('batch_concat',np.array(batch_concat_one_hot_list).shape)\n",
    "    print('batch_label', np.array(batch_label_one_hot_list).shape)\n",
    "\n",
    "    output:\n",
    "    batch_concat (50, 2075, 217) # 217 is concatenated vector dimension, N * m * d\n",
    "    batch_label (50, 2075, 112) # 112 is the char encoded vector dimension, N * m * v\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.tensor(np.array(batch_concat_one_hot_list)).float(), torch.tensor(np.array(batch_label_one_hot_list)).float()\n",
    "    \n",
    "\n",
    "    \n",
    "def train_valid_split(data, labels):\n",
    "    # TODO: Takes in train data and labels as numpy array (or a torch Tensor/ Variable) and\n",
    "    # splits it into training and validation data.\n",
    "    training_percentage = 0.8 # 80 / 20 split\n",
    "    training_size = len(data) * training_percentage\n",
    "    X_train = data[:training_size]\n",
    "    y_train = labels[:training_size]\n",
    "    \n",
    "    X_valid = data[training_size:]\n",
    "    y_valid = labels[training_size:]\n",
    "\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "\n",
    "def train_valid_split(df):\n",
    "    # TODO: Takes in dataframe and\n",
    "    # splits it into training dataframe and validation dataframe.\n",
    "    size = len(df)\n",
    "    split = int(0.9*size)\n",
    "    train_df = df[:split]\n",
    "    val_df = df[split:]\n",
    "    return train_df, val_df\n",
    "\n",
    "    \n",
    "    \n",
    "def process_test_data(data):\n",
    "    # TODO: Takes in pandas DataFrame and returns a numpy array (or a torch Tensor/ Variable)\n",
    "    # that has all input features. Note that test data does not contain any review so you don't\n",
    "    # have to worry about one hot encoding the data.\n",
    "    for index, row in data.iteraterow():\n",
    "        beer_style, review_overall = row['beer/style'], row['review/overall']\n",
    "        concat_one_hot_list = []\n",
    "        label_one_hot_list = []\n",
    "        # Meta feature vector should be fixed per review\n",
    "        beer_style_one_hot = [0] * len(BEER_STYLE_ARRAY)\n",
    "        if beer_style in BEER_STYLE_RECORD:\n",
    "            beer_style_one_hot[BEER_STYLE_RECORD[beer_style]] = 1\n",
    "            review_overall_one_hot = [review_overall]\n",
    "            meta_data_feature_vector_one_hot = review_overall_one_hot + beer_style_one_hot\n",
    "    return None\n",
    "\n",
    "\n",
    "# this function should be called inside the train function\n",
    "def pad_data(orig_data):\n",
    "    # TODO: Since you will be training in batches and training sample of each batch may have reviews\n",
    "    # of varying lengths, you will need to pad your data so that all samples have reviews of length\n",
    "    # equal to the longest review in a batch. You will pad all the sequences with <EOS> character \n",
    "    # representation in one hot encoding.\n",
    "    \n",
    "    \"\"\"\n",
    "    orig_data : \n",
    "    [\n",
    "        ['oh(< SOS >)', 'oh(a)', 'oh(b)', 'oh(c)', 'oh< EOS >'],  # review 1\n",
    "        ['oh(< SOS >)', 'oh(h)', 'oh(e)', 'oh(l)', 'oh(l)', 'oh(o)','oh< EOS >']  # review 2\n",
    "        ['oh(< SOS >)', 'oh(y)', 'oh(e)', 'oh< EOS >']  # review 3\n",
    "    ]\n",
    "    \"\"\"\n",
    "  \n",
    "    max_len = max([len(element) for element in orig_data])\n",
    "    for element in orig_data: #TODO fix runtime\n",
    "        l = len(element)\n",
    "        if l < max_len:\n",
    "            # need to pad this element\n",
    "            eos_oh = char2oh('< EOS >')\n",
    "            eos_to_pad = [eos_oh] * (max_len - l)\n",
    "            element += eos_to_pad #TODO fix this. delegate this to the GPU\n",
    "    return orig_data\n",
    "\n",
    "\n",
    "def train(model, X_train, y_train, cfg):\n",
    "    \n",
    "    model.zero_grad()\n",
    "    model.hidden = model.init_hidden() # reset the hidden state\n",
    "    y_train = np.argmax(y_train, axis=2).view(-1)\n",
    "    train_outputs = model(X_train) \n",
    "    train_outputs = train_outputs.view(train_outputs.shape[0]*train_outputs.shape[1], -1)\n",
    "    traing_loss = loss_function(train_outputs, y_train.cuda())\n",
    "    traing_loss.backward()\n",
    "    optimizer.step() # weight update\n",
    "    \n",
    "    return traing_loss\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def generate(model, X_test, cfg):\n",
    "    # TODO: Given n rows in test data, generate a list of n strings, where each string is the review\n",
    "    # corresponding to each input row in test data.\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    \n",
    "def save_to_file(outputs, fname):\n",
    "    # TODO: Given the list of generated review outputs and output file name, save all these reviews to\n",
    "    # the file in .txt format.\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    #declare model\n",
    "    model = baselineLSTM(cfg) # Replace this with model = <your model name>(cfg)\n",
    "    # TODO: Train the model!\n",
    "    loss_function = nn.CrossEntropyLoss()    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    if cfg['cuda']:\n",
    "        print(\"cuda availabe\")\n",
    "        computing_device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"cuda not availabe\")\n",
    "        computing_device = torch.device(\"cpu\")\n",
    "    model.to(computing_device)\n",
    "    \n",
    "    train_data_fname = \"Beeradvocate_Train.csv\"\n",
    "    test_data_fname = \"Beeradvocate_Test.csv\"\n",
    "    out_fname = \"\"\n",
    "    \n",
    "    #load data to df\n",
    "    train_data = load_data(train_data_fname) # Generating the pandas DataFrame\n",
    "    test_data = load_data(test_data_fname) # Generating the pandas DataFrame\n",
    "    #split df to training and validation\n",
    "    train_df, val_df = train_valid_split(train_data)\n",
    "    \n",
    "    # train_data = train_data.head(n=100) # TODO: remove this when perform actual training\n",
    "    # divide training df into even chunks\n",
    "    train_df = train_df.head(n=(len(train_df) // cfg['batch_size']) * cfg['batch_size']) # get rid of extra rows for even split \n",
    "    split = len(train_df) // cfg['batch_size'] # num of minibatches\n",
    "    train_data_chunks = np.array_split(train_df, split) #chunks of dataframe \n",
    "    \n",
    "    val_df = val_df.head(n = 100)\n",
    "    val_df = val_df.head(n=(len(val_df) // cfg['batch_size']) * cfg['batch_size']) # get rid of extra rows for even split \n",
    "    split = len(val_df) // cfg['batch_size'] # num of minibatches\n",
    "    val_data_chunks = np.array_split(val_df, split) #chunks of dataframe \n",
    "    \n",
    "    print(len(train_data_chunks))\n",
    "\n",
    "    record_size = int(len(train_data_chunks) / 10) #record training accuracy every 10 chunks\n",
    "    val_data, val_labels = None, None\n",
    "    \n",
    "\n",
    "    # train over each epoch\n",
    "    for epoch in range(cfg['epochs']):  \n",
    "        #train in chunks\n",
    "        train_loss_total = 0\n",
    "        \n",
    "        \n",
    "        for index, chunk in enumerate(train_data_chunks):\n",
    "            # pre-process the data on-line\n",
    "            train_data, train_labels = process_train_data(chunk, cfg)\n",
    "            train_loss = train(model, train_data, train_labels, cfg)\n",
    "            train_loss_total += train_loss\n",
    "            \n",
    "\n",
    "            if index != 0 and  index % record_size == 0:\n",
    "                train_loss_avg = train_loss_total / record_size\n",
    "                print(\"average train_loss: \", train_loss_avg.item())\n",
    "                train_loss_total = 0\n",
    "                \n",
    "                val_loss_total = 0\n",
    "                for val_chunk in val_data_chunks:\n",
    "                    # validation loss\n",
    "                    X_valid, y_valid = process_train_data(val_chunk, cfg)\n",
    "                    y_valid = np.argmax(y_valid, axis=2).view(-1)\n",
    "                    val_outputs = model(X_valid) \n",
    "                    val_outputs = val_outputs.view(val_outputs.shape[0]*val_outputs.shape[1], -1)\n",
    "                    val_loss = loss_function(val_outputs, y_valid.cuda())\n",
    "                    val_loss_total += val_loss\n",
    "                val_loss_avg = val_loss_total / len(val_data_chunks) # loss per batch size\n",
    "                print(\"average val_loss: \", val_loss_avg.item())\n",
    "                \n",
    "    \"\"\"\n",
    "    # TODO: Work on the train_valid_split\n",
    "    X_train, y_train, X_valid, y_valid = train_valid_split(train_data, train_labels) # Splitting the train data into train-valid data\n",
    "    \n",
    "    \n",
    "    # TODO: Work on the process_test_data\n",
    "    X_test = process_test_data(test_data) # Converting DataFrame to numpy array\n",
    "    \n",
    "    model = baselineLSTM(cfg) # Replace this with model = <your model name>(cfg)\n",
    "    if cfg['cuda']:\n",
    "        computing_device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        computing_device = torch.device(\"cpu\")\n",
    "    model.to(computing_device)\n",
    "    \n",
    "    train(model, X_train, y_train, X_valid, y_valid, cfg) # Train the model, we should perform the encoding per mini-batch basis\n",
    "    outputs = generate(model, X_test, cfg) # Generate the outputs for test data\n",
    "    \n",
    "    # TODO: Work on the save_to_file\n",
    "    save_to_file(outputs, out_fname) # Save the generated outputs to a file\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
