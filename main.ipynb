{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_concat (50, 2075, 217)\n",
      "batch_label (50, 2075, 112)\n",
      "batch_concat (50, 1945, 217)\n",
      "batch_label (50, 1945, 112)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from models import *\n",
    "from configs import cfg\n",
    "import pandas as pd\n",
    "from nltk.translate import bleu_score\n",
    "import pickle\n",
    "\n",
    "\n",
    "def saveVocabulary(vocabulary):\n",
    "    #note loaders are saved already\n",
    "    data = {}\n",
    "    data['vocabulary'] = vocabulary\n",
    "    print(\"start saving vocabulary to pickle\")\n",
    "    with open('vocabulary.pickle','wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL) \n",
    "        print(\"finished writing to pickle\")\n",
    "\n",
    "def getVocabulary():\n",
    "    with open('vocabulary.pickle','rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "    return data['vocabulary']\n",
    "\n",
    "\n",
    "VOCABULARY = getVocabulary()\n",
    "VOCABULARY_FLIP = dict((v,k) for k,v in VOCABULARY.items()) \n",
    "\n",
    "BEER_STYLE_ARRAY = ['Old Ale', 'Bière de Champagne / Bière Brut', 'American Amber / Red Ale', 'Oatmeal Stout', 'Belgian Dark Ale', 'Schwarzbier', 'Witbier', 'Weizenbock', 'English Brown Ale', 'Irish Dry Stout', 'Fruit / Vegetable Beer', 'Japanese Rice Lager', 'English Dark Mild Ale', 'Maibock / Helles Bock', 'Czech Pilsener', 'German Pilsener', 'American Pale Ale (APA)', 'Rauchbier', 'American Malt Liquor', 'American Amber / Red Lager', 'American Pale Wheat Ale', 'Märzen / Oktoberfest', 'English Porter', 'Euro Pale Lager', 'Scotch Ale / Wee Heavy', 'American Stout', 'Belgian Strong Pale Ale', 'American Brown Ale', 'Pumpkin Ale', 'Lambic - Fruit', 'Altbier', 'Bière de Garde', 'Lambic - Unblended', 'English Strong Ale', 'Sahti', 'Eisbock', 'Dortmunder / Export Lager', 'English Pale Ale', 'Gose', 'Kölsch', 'American Dark Wheat Ale', 'Berliner Weissbier', 'Euro Strong Lager', 'Low Alcohol Beer', 'English Stout', 'Rye Beer', 'American IPA', 'Happoshu', 'American Blonde Ale', 'American Adjunct Lager', 'American Black Ale', 'Black & Tan', 'California Common / Steam Beer', 'Munich Dunkel Lager', 'Munich Helles Lager', 'English Barleywine', 'Kristalweizen', 'Vienna Lager', 'Wheatwine', 'English India Pale Ale (IPA)', 'Braggot', 'Smoked Beer', 'Doppelbock', 'Milk / Sweet Stout', 'Scottish Ale', 'Cream Ale', 'Belgian Strong Dark Ale', 'Scottish Gruit / Ancient Herbed Ale', 'Faro', 'Hefeweizen', 'Dunkelweizen', 'Russian Imperial Stout', 'American Porter', 'American Strong Ale', 'Gueuze', 'Euro Dark Lager', 'Roggenbier', 'Keller Bier / Zwickel Bier', 'Extra Special / Strong Bitter (ESB)', 'American Double / Imperial Stout', 'Irish Red Ale', 'Foreign / Export Stout', 'Belgian IPA', 'English Bitter', 'English Pale Mild Ale', 'American Pale Lager', 'Baltic Porter', 'Kvass', 'Light Lager', 'Tripel', 'Flanders Red Ale', 'American Wild Ale', 'Saison / Farmhouse Ale', 'Belgian Pale Ale', 'American Double / Imperial Pilsner', 'Dubbel', 'American Double / Imperial IPA', 'Bock', 'Chile Beer', 'Herbed / Spiced Beer', 'Flanders Oud Bruin', 'Winter Warmer', 'Quadrupel (Quad)', 'American Barleywine']\n",
    "BEER_STYLE_RECORD = {k: v for v, k in enumerate(BEER_STYLE_ARRAY)} # {'Old Ale': 0, 'Bière de Champagne / Bière Brut', 1 ...}\n",
    "\n",
    "\n",
    "def char2oh(c):\n",
    "    oh = [0] * len(VOCABULARY)\n",
    "    c_index = VOCABULARY[c] if c in VOCABULARY else VOCABULARY['< UNK >']\n",
    "    oh[c_index] = 1\n",
    "    return oh\n",
    "\n",
    "def oh2char(oh):\n",
    "    if len(oh) > len(VOCABULARY_FLIP):\n",
    "        return None\n",
    "    for index, e in enumerate(oh):\n",
    "        if e == 1:\n",
    "            return VOCABULARY_FLIP[index]\n",
    "    return None\n",
    "    \n",
    "\n",
    "def load_data(fname):\n",
    "    # TODO: From the csv file given by filename and return a pandas DataFrame of the read csv.\n",
    "    return pd.read_csv(fname)\n",
    "\n",
    "# save the vocabulary\n",
    "\"\"\"\n",
    "# save the vocabulary to pickle\n",
    "vocabularySet = set()\n",
    "vocabularySet.add('< SOS >')\n",
    "vocabularySet.add('< EOS >')\n",
    "vocabularySet.add('< UNK >')\n",
    "for index, row in data.iterrows():\n",
    "    review_text = list((str(row['review/text'])))\n",
    "    for c in review_text:\n",
    "        vocabularySet.add(c)\n",
    "vocabulary_record = {k: v for v, k in enumerate(vocabularySet)}\n",
    "saveVocabulary(vocabulary_record)\n",
    "\"\"\"\n",
    "\n",
    "# The data should be per mini-batch basis, https://piazza.com/class/jml6wogpji0o3?cid=450\n",
    "def process_train_data(data, cfg):\n",
    "    # TODO: Input is a pandas DataFrame and return a numpy array (or a torch Tensor/ Variable)\n",
    "    # that has all features (including characters in one hot encoded form).\n",
    "    # don't perform one-hot encoding here for all the dataframe, otherwise, you will get a memory issue\n",
    "    # the one-hot encoding should be per mini-batch basis\n",
    "    \n",
    "    \"\"\"\n",
    "    Let the final input after concatenation of metadata feature vector and one hot encoded representation be\n",
    "    a d dimensional vector. In this case, your input for processed training data will be of size N × m × d,\n",
    "    and labels will be of size N × m × v, where v is the length of one hot encoded vector\n",
    "    \"\"\"\n",
    "    data = data.head(n=100) # TODO: remove this when perform actual training\n",
    "    data = data.head(n=(len(data) // cfg['batch_size']) * cfg['batch_size']) # get rid of extra rows for even split \n",
    "    \n",
    "    split = len(data) // cfg['batch_size']\n",
    "    # 25385 chunks where each chunk contains 50 rows\n",
    "    \n",
    "    processed_input_data = []\n",
    "    processed_label_data = []\n",
    "    \n",
    "    for chunk in np.array_split(data, split):\n",
    "        batch_c_one_hot_list = []\n",
    "        # pad the char one hot encoding\n",
    "        for index, row in chunk.iterrows():\n",
    "            c_one_hot_list = []\n",
    "            review_text = list((str(row['review/text'])))\n",
    "            review_text.insert(0, '< SOS >')\n",
    "            review_text.append('< EOS >')\n",
    "            for c in review_text:\n",
    "                c_one_hot = char2oh(c) # 217\n",
    "                c_one_hot_list.append(c_one_hot)\n",
    "            batch_c_one_hot_list.append(c_one_hot_list)\n",
    "        batch_c_one_hot_list = pad_data(batch_c_one_hot_list)\n",
    "        \n",
    "        batch_concat_one_hot_list = []   \n",
    "        batch_label_one_hot_list = []\n",
    "        for index, row in chunk.iterrows():\n",
    "            beer_style, review_overall = row['beer/style'], row['review/overall']\n",
    "            concat_one_hot_list = []\n",
    "            label_one_hot_list = []\n",
    "            # Meta feature vector should be fixed per review\n",
    "            beer_style_one_hot = [0] * len(BEER_STYLE_ARRAY)\n",
    "            if beer_style in BEER_STYLE_RECORD:\n",
    "                beer_style_one_hot[BEER_STYLE_RECORD[beer_style]] = 1\n",
    "                review_overall_one_hot = [review_overall]\n",
    "                meta_data_feature_vector_one_hot = review_overall_one_hot + beer_style_one_hot\n",
    "                # generate the concatenated one hot representation\n",
    "                for c_one_hot in batch_c_one_hot_list[index%cfg['batch_size']]:\n",
    "                    concat_one_hot = meta_data_feature_vector_one_hot + c_one_hot # dimension 217(with concatenation), input, current char\n",
    "                    concat_one_hot_list.append(concat_one_hot)\n",
    "                    # dimension 112, lable/output, next char\n",
    "                    label_one_hot_list.append(c_one_hot)\n",
    "                batch_concat_one_hot_list.append(concat_one_hot_list)\n",
    "                # label\n",
    "                label_one_hot_list = label_one_hot_list[1:] + [char2oh('< EOS >')] # shift 1 element to point to next char\n",
    "                batch_label_one_hot_list.append(label_one_hot_list)\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        \"\"\" DEBUG PRINT\n",
    "        print('batch_concat',np.array(batch_concat_one_hot_list).shape)\n",
    "        print('batch_label', np.array(batch_label_one_hot_list).shape)\n",
    "        batch_concat (50, 2075, 217) # 217 is concatenated vector dimension, N * m * d\n",
    "        batch_label (50, 2075, 112) # 112 is the char encoded vector dimension, N * m * v\n",
    "        \"\"\"\n",
    "        \n",
    "        processed_input_data.append(batch_concat_one_hot_list)\n",
    "        processed_label_data.append(batch_label_one_hot_list)\n",
    "           \n",
    "    return np.array(processed_input_data), np.array(processed_label_data)\n",
    "    \n",
    "\n",
    "    \n",
    "def train_valid_split(data, labels):\n",
    "    # TODO: Takes in train data and labels as numpy array (or a torch Tensor/ Variable) and\n",
    "    # splits it into training and validation data.\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    \n",
    "def process_test_data(data):\n",
    "    # TODO: Takes in pandas DataFrame and returns a numpy array (or a torch Tensor/ Variable)\n",
    "    # that has all input features. Note that test data does not contain any review so you don't\n",
    "    # have to worry about one hot encoding the data.\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "# this function should be called inside the train function\n",
    "def pad_data(orig_data):\n",
    "    # TODO: Since you will be training in batches and training sample of each batch may have reviews\n",
    "    # of varying lengths, you will need to pad your data so that all samples have reviews of length\n",
    "    # equal to the longest review in a batch. You will pad all the sequences with <EOS> character \n",
    "    # representation in one hot encoding.\n",
    "    \n",
    "    \"\"\"\n",
    "    orig_data : \n",
    "    [\n",
    "        ['oh(< SOS >)', 'oh(a)', 'oh(b)', 'oh(c)', 'oh< EOS >'],  # review 1\n",
    "        ['oh(< SOS >)', 'oh(h)', 'oh(e)', 'oh(l)', 'oh(l)', 'oh(o)','oh< EOS >']  # review 2\n",
    "        ['oh(< SOS >)', 'oh(y)', 'oh(e)', 'oh< EOS >']  # review 3\n",
    "    ]\n",
    "    \"\"\"\n",
    "  \n",
    "    max_len = max([len(element) for element in orig_data])\n",
    "    for element in orig_data:\n",
    "        l = len(element)\n",
    "        if l < max_len:\n",
    "            # need to pad this element\n",
    "            eos_oh = char2oh('< EOS >')\n",
    "            eos_to_pad = [eos_oh] * (max_len - l)\n",
    "            element += eos_to_pad\n",
    "    return orig_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(model, X_train, y_train, X_valid, y_valid, cfg):\n",
    "    # TODO: Train the model!\n",
    "#     for epoch in range(cfg['epochs']):  \n",
    "#         mini_batch_train_data\n",
    "#         for (beer_style, review_overall, review_text) in X_train:\n",
    "            \n",
    "            \n",
    "#             #  do the encoding transformation on a per-batch basis. \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    raise NotImplementedError\n",
    "    \n",
    "    \n",
    "def generate(model, X_test, cfg):\n",
    "    # TODO: Given n rows in test data, generate a list of n strings, where each string is the review\n",
    "    # corresponding to each input row in test data.\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    \n",
    "def save_to_file(outputs, fname):\n",
    "    # TODO: Given the list of generated review outputs and output file name, save all these reviews to\n",
    "    # the file in .txt format.\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_data_fname = \"Beeradvocate_Train.csv\"\n",
    "    test_data_fname = \"Beeradvocate_Test.csv\"\n",
    "    out_fname = \"\"\n",
    "\n",
    "    train_data = load_data(train_data_fname) # Generating the pandas DataFrame\n",
    "    test_data = load_data(test_data_fname) # Generating the pandas DataFrame\n",
    "\n",
    "    process_train_data(train_data, cfg)\n",
    "#     train_data, train_labels = process_train_data(train_data) # Converting DataFrame to numpy array\n",
    "\n",
    "    \n",
    "    \n",
    "    #     X_train, y_train, X_valid, y_valid = train_valid_split(train_data, train_labels) # Splitting the train data into train-valid data\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    X_test = process_test_data(test_data) # Converting DataFrame to numpy array\n",
    "    \n",
    "    model = baselineLSTM(cfg) # Replace this with model = <your model name>(cfg)\n",
    "    if cfg['cuda']:\n",
    "        computing_device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        computing_device = torch.device(\"cpu\")\n",
    "    model.to(computing_device)\n",
    "    \n",
    "    train(model, X_train, y_train, X_valid, y_valid, cfg) # Train the model\n",
    "    outputs = generate(model, X_test, cfg) # Generate the outputs for test data\n",
    "    save_to_file(outputs, out_fname) # Save the generated outputs to a file\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
