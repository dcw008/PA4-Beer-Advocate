{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda availabe\n",
      "init from baselineLSTM\n",
      "cuda availabe\n",
      "y train dimension torch.Size([50, 2075])\n",
      "cuda availabe\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected target size (50, 112), got torch.Size([50, 2075])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e1050eee94b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;31m# pre-process the data on-line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-e1050eee94b8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, X_train, y_train, X_valid, y_valid, cfg)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         return F.cross_entropy(input, target, self.weight, self.size_average,\n\u001b[0;32m--> 759\u001b[0;31m                                self.ignore_index, self.reduce)\n\u001b[0m\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m     \"\"\"\n\u001b[0;32m-> 1442\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m             raise ValueError('Expected target size {}, got {}'.format(\n\u001b[0;32m-> 1341\u001b[0;31m                 out_size, target.size()))\n\u001b[0m\u001b[1;32m   1342\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected target size (50, 112), got torch.Size([50, 2075])"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from models import *\n",
    "from configs import cfg\n",
    "import pandas as pd\n",
    "from nltk.translate import bleu_score\n",
    "import pickle\n",
    "\n",
    "\n",
    "def saveVocabulary(vocabulary):\n",
    "    #note loaders are saved already\n",
    "    data = {}\n",
    "    data['vocabulary'] = vocabulary\n",
    "    print(\"start saving vocabulary to pickle\")\n",
    "    with open('vocabulary.pickle','wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL) \n",
    "        print(\"finished writing to pickle\")\n",
    "\n",
    "def getVocabulary():\n",
    "    with open('vocabulary.pickle','rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "    return data['vocabulary']\n",
    "\n",
    "\n",
    "VOCABULARY = getVocabulary()\n",
    "VOCABULARY_FLIP = dict((v,k) for k,v in VOCABULARY.items()) \n",
    "\n",
    "BEER_STYLE_ARRAY = ['Old Ale', 'Bière de Champagne / Bière Brut', 'American Amber / Red Ale', 'Oatmeal Stout', 'Belgian Dark Ale', 'Schwarzbier', 'Witbier', 'Weizenbock', 'English Brown Ale', 'Irish Dry Stout', 'Fruit / Vegetable Beer', 'Japanese Rice Lager', 'English Dark Mild Ale', 'Maibock / Helles Bock', 'Czech Pilsener', 'German Pilsener', 'American Pale Ale (APA)', 'Rauchbier', 'American Malt Liquor', 'American Amber / Red Lager', 'American Pale Wheat Ale', 'Märzen / Oktoberfest', 'English Porter', 'Euro Pale Lager', 'Scotch Ale / Wee Heavy', 'American Stout', 'Belgian Strong Pale Ale', 'American Brown Ale', 'Pumpkin Ale', 'Lambic - Fruit', 'Altbier', 'Bière de Garde', 'Lambic - Unblended', 'English Strong Ale', 'Sahti', 'Eisbock', 'Dortmunder / Export Lager', 'English Pale Ale', 'Gose', 'Kölsch', 'American Dark Wheat Ale', 'Berliner Weissbier', 'Euro Strong Lager', 'Low Alcohol Beer', 'English Stout', 'Rye Beer', 'American IPA', 'Happoshu', 'American Blonde Ale', 'American Adjunct Lager', 'American Black Ale', 'Black & Tan', 'California Common / Steam Beer', 'Munich Dunkel Lager', 'Munich Helles Lager', 'English Barleywine', 'Kristalweizen', 'Vienna Lager', 'Wheatwine', 'English India Pale Ale (IPA)', 'Braggot', 'Smoked Beer', 'Doppelbock', 'Milk / Sweet Stout', 'Scottish Ale', 'Cream Ale', 'Belgian Strong Dark Ale', 'Scottish Gruit / Ancient Herbed Ale', 'Faro', 'Hefeweizen', 'Dunkelweizen', 'Russian Imperial Stout', 'American Porter', 'American Strong Ale', 'Gueuze', 'Euro Dark Lager', 'Roggenbier', 'Keller Bier / Zwickel Bier', 'Extra Special / Strong Bitter (ESB)', 'American Double / Imperial Stout', 'Irish Red Ale', 'Foreign / Export Stout', 'Belgian IPA', 'English Bitter', 'English Pale Mild Ale', 'American Pale Lager', 'Baltic Porter', 'Kvass', 'Light Lager', 'Tripel', 'Flanders Red Ale', 'American Wild Ale', 'Saison / Farmhouse Ale', 'Belgian Pale Ale', 'American Double / Imperial Pilsner', 'Dubbel', 'American Double / Imperial IPA', 'Bock', 'Chile Beer', 'Herbed / Spiced Beer', 'Flanders Oud Bruin', 'Winter Warmer', 'Quadrupel (Quad)', 'American Barleywine']\n",
    "BEER_STYLE_RECORD = {k: v for v, k in enumerate(BEER_STYLE_ARRAY)} # {'Old Ale': 0, 'Bière de Champagne / Bière Brut', 1 ...}\n",
    "\n",
    "\n",
    "def char2oh(c):\n",
    "    oh = [0] * len(VOCABULARY)\n",
    "    c_index = VOCABULARY[c] if c in VOCABULARY else VOCABULARY['< UNK >']\n",
    "    oh[c_index] = 1\n",
    "    return oh\n",
    "\n",
    "def oh2char(oh):\n",
    "    if len(oh) > len(VOCABULARY_FLIP):\n",
    "        return None\n",
    "    for index, e in enumerate(oh):\n",
    "        if e == 1:\n",
    "            return VOCABULARY_FLIP[index]\n",
    "    return None\n",
    "    \n",
    "\n",
    "def load_data(fname):\n",
    "    # TODO: From the csv file given by filename and return a pandas DataFrame of the read csv.\n",
    "    return pd.read_csv(fname)\n",
    "\n",
    "# save the vocabulary\n",
    "\"\"\"\n",
    "# save the vocabulary to pickle\n",
    "vocabularySet = set()\n",
    "vocabularySet.add('< SOS >')\n",
    "vocabularySet.add('< EOS >')\n",
    "vocabularySet.add('< UNK >')\n",
    "for index, row in data.iterrows():\n",
    "    review_text = list((str(row['review/text'])))\n",
    "    for c in review_text:\n",
    "        vocabularySet.add(c)\n",
    "vocabulary_record = {k: v for v, k in enumerate(vocabularySet)}\n",
    "saveVocabulary(vocabulary_record)\n",
    "\"\"\"\n",
    "\n",
    "# The data should be per mini-batch basis, https://piazza.com/class/jml6wogpji0o3?cid=450\n",
    "def process_train_data(chunk, cfg):\n",
    "    # TODO: Input is a pandas DataFrame and return a numpy array (or a torch Tensor/ Variable)\n",
    "    # that has all features (including characters in one hot encoded form).\n",
    "    # don't perform one-hot encoding here for all the dataframe, otherwise, you will get a memory issue\n",
    "    # the one-hot encoding should be per mini-batch basis\n",
    "    \n",
    "    \"\"\"\n",
    "    Let the final input after concatenation of metadata feature vector and one hot encoded representation be\n",
    "    a d dimensional vector. In this case, your input for processed training data will be of size N × m × d,\n",
    "    and labels will be of size N × m × v, where v is the length of one hot encoded vector\n",
    "    \"\"\"\n",
    "        \n",
    "    batch_c_one_hot_list = []\n",
    "    # pad the char one hot encoding\n",
    "    for index, row in chunk.iterrows():\n",
    "        c_one_hot_list = []\n",
    "        review_text = list((str(row['review/text'])))\n",
    "        review_text.insert(0, '< SOS >')\n",
    "        review_text.append('< EOS >')\n",
    "        for c in review_text:\n",
    "            c_one_hot = char2oh(c) # 217\n",
    "            c_one_hot_list.append(c_one_hot)\n",
    "        batch_c_one_hot_list.append(c_one_hot_list)\n",
    "    batch_c_one_hot_list = pad_data(batch_c_one_hot_list)\n",
    "\n",
    "    batch_concat_one_hot_list = []   \n",
    "    batch_label_one_hot_list = []\n",
    "    for index, row in chunk.iterrows():\n",
    "        beer_style, review_overall = row['beer/style'], row['review/overall']\n",
    "        concat_one_hot_list = []\n",
    "        label_one_hot_list = []\n",
    "        # Meta feature vector should be fixed per review\n",
    "        beer_style_one_hot = [0] * len(BEER_STYLE_ARRAY)\n",
    "        if beer_style in BEER_STYLE_RECORD:\n",
    "            beer_style_one_hot[BEER_STYLE_RECORD[beer_style]] = 1\n",
    "            review_overall_one_hot = [review_overall]\n",
    "            meta_data_feature_vector_one_hot = review_overall_one_hot + beer_style_one_hot\n",
    "            # generate the concatenated one hot representation\n",
    "            for c_one_hot in batch_c_one_hot_list[index%cfg['batch_size']]:\n",
    "                concat_one_hot = c_one_hot + meta_data_feature_vector_one_hot # dimension 217(with concatenation), input, current char\n",
    "                concat_one_hot_list.append(concat_one_hot)\n",
    "                # dimension 112, lable/output, next char\n",
    "                label_one_hot_list.append(c_one_hot)\n",
    "            batch_concat_one_hot_list.append(concat_one_hot_list)\n",
    "            # label\n",
    "            label_one_hot_list = label_one_hot_list[1:] + [char2oh('< EOS >')] # shift 1 element to point to next char\n",
    "            batch_label_one_hot_list.append(label_one_hot_list)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    \"\"\" DEBUG PRINT\n",
    "    print('batch_concat',np.array(batch_concat_one_hot_list).shape)\n",
    "    print('batch_label', np.array(batch_label_one_hot_list).shape)\n",
    "\n",
    "    output:\n",
    "    batch_concat (50, 2075, 217) # 217 is concatenated vector dimension, N * m * d\n",
    "    batch_label (50, 2075, 112) # 112 is the char encoded vector dimension, N * m * v\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.tensor(np.array(batch_concat_one_hot_list)).float(), torch.tensor(np.array(batch_label_one_hot_list)).float()\n",
    "    \n",
    "\n",
    "    \n",
    "def train_valid_split(data, labels):\n",
    "    # TODO: Takes in train data and labels as numpy array (or a torch Tensor/ Variable) and\n",
    "    # splits it into training and validation data.\n",
    "    training_percentage = 0.8 # 80 / 20 split\n",
    "    training_size = len(data) * training_percentage\n",
    "    X_train = data[:training_size]\n",
    "    y_train = labels[:training_size]\n",
    "    \n",
    "    X_valid = data[training_size:]\n",
    "    y_valid = labels[training_size:]\n",
    "\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "\n",
    "def train_valid_split(df):\n",
    "    # TODO: Takes in dataframe and\n",
    "    # splits it into training dataframe and validation dataframe.\n",
    "    size = len(df)\n",
    "    split = int(0.9*size)\n",
    "    train_df = df[:split]\n",
    "    val_df = df[split:]\n",
    "    return train_df, val_df\n",
    "\n",
    "    \n",
    "    \n",
    "def process_test_data(data):\n",
    "    # TODO: Takes in pandas DataFrame and returns a numpy array (or a torch Tensor/ Variable)\n",
    "    # that has all input features. Note that test data does not contain any review so you don't\n",
    "    # have to worry about one hot encoding the data.\n",
    "    for index, row in data.iteraterow():\n",
    "        beer_style, review_overall = row['beer/style'], row['review/overall']\n",
    "        concat_one_hot_list = []\n",
    "        label_one_hot_list = []\n",
    "        # Meta feature vector should be fixed per review\n",
    "        beer_style_one_hot = [0] * len(BEER_STYLE_ARRAY)\n",
    "        if beer_style in BEER_STYLE_RECORD:\n",
    "            beer_style_one_hot[BEER_STYLE_RECORD[beer_style]] = 1\n",
    "            review_overall_one_hot = [review_overall]\n",
    "            meta_data_feature_vector_one_hot = review_overall_one_hot + beer_style_one_hot\n",
    "    return None\n",
    "\n",
    "\n",
    "# this function should be called inside the train function\n",
    "def pad_data(orig_data):\n",
    "    # TODO: Since you will be training in batches and training sample of each batch may have reviews\n",
    "    # of varying lengths, you will need to pad your data so that all samples have reviews of length\n",
    "    # equal to the longest review in a batch. You will pad all the sequences with <EOS> character \n",
    "    # representation in one hot encoding.\n",
    "    \n",
    "    \"\"\"\n",
    "    orig_data : \n",
    "    [\n",
    "        ['oh(< SOS >)', 'oh(a)', 'oh(b)', 'oh(c)', 'oh< EOS >'],  # review 1\n",
    "        ['oh(< SOS >)', 'oh(h)', 'oh(e)', 'oh(l)', 'oh(l)', 'oh(o)','oh< EOS >']  # review 2\n",
    "        ['oh(< SOS >)', 'oh(y)', 'oh(e)', 'oh< EOS >']  # review 3\n",
    "    ]\n",
    "    \"\"\"\n",
    "  \n",
    "    max_len = max([len(element) for element in orig_data])\n",
    "    for element in orig_data:\n",
    "        l = len(element)\n",
    "        if l < max_len:\n",
    "            # need to pad this element\n",
    "            eos_oh = char2oh('< EOS >')\n",
    "            eos_to_pad = [eos_oh] * (max_len - l)\n",
    "            element += eos_to_pad\n",
    "    return orig_data\n",
    "\n",
    "\n",
    "def train(model, X_train, y_train, X_valid, y_valid, cfg):\n",
    "    # TODO: Train the model!\n",
    "    loss_function = nn.CrossEntropyLoss()    \n",
    "\n",
    "   \n",
    "    print(\"y train dimension\", y_train.shape)\n",
    "    \n",
    "    model.zero_grad()\n",
    "    # Also, we need to clear out the hidden state of the LSTM,\n",
    "    # detaching it from its history on the last instance.\n",
    "    model.hidden = model.init_hidden() # reset the hidden state\n",
    "    \n",
    "    \n",
    "    \n",
    "    y_train = np.argmax(y_train, axis=2) # reduce the dimension to N * m * 1\n",
    "    outputs = model(X_train)\n",
    "    loss = loss_function(outputs, y_train)\n",
    "    loss.backward()\n",
    "    print('training loss', loss.item)\n",
    "    optimizer.step()\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "    \n",
    "def generate(model, X_test, cfg):\n",
    "    # TODO: Given n rows in test data, generate a list of n strings, where each string is the review\n",
    "    # corresponding to each input row in test data.\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    \n",
    "def save_to_file(outputs, fname):\n",
    "    # TODO: Given the list of generated review outputs and output file name, save all these reviews to\n",
    "    # the file in .txt format.\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    #declare model\n",
    "    model = baselineLSTM(cfg) # Replace this with model = <your model name>(cfg)\n",
    "    if cfg['cuda']:\n",
    "        print(\"cuda availabe\")\n",
    "        computing_device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"cuda not availabe\")\n",
    "        computing_device = torch.device(\"cpu\")\n",
    "    model.to(computing_device)\n",
    "    \n",
    "    train_data_fname = \"Beeradvocate_Train.csv\"\n",
    "    test_data_fname = \"Beeradvocate_Test.csv\"\n",
    "    out_fname = \"\"\n",
    "    \n",
    "    #load data to df\n",
    "    train_data = load_data(train_data_fname) # Generating the pandas DataFrame\n",
    "    test_data = load_data(test_data_fname) # Generating the pandas DataFrame\n",
    "    #split df to training and validation\n",
    "    train_df, val_df = train_valid_split(train_data)\n",
    "    \n",
    "    # train_data = train_data.head(n=100) # TODO: remove this when perform actual training\n",
    "    # divide training df into even chunks\n",
    "    train_df = train_df.head(n=(len(train_df) // cfg['batch_size']) * cfg['batch_size']) # get rid of extra rows for even split \n",
    "\n",
    "    split = len(train_df) // cfg['batch_size'] # num of minibatches\n",
    "    train_data_chunks = np.array_split(train_df, split) #chunks of dataframe \n",
    "    \n",
    "    #get data and labels from val_df to ohc\n",
    "    # TODO: Clarify if we need to do the average corss validation so that we don't run into memory issue      \n",
    "#     val_data, val_labels = process_train_data(val_df, cfg) \n",
    "\n",
    "    val_data, val_labels = None, None\n",
    "    \n",
    "    # train over each epoch\n",
    "    for epoch in range(cfg['epochs']):  \n",
    "        #train in chunks\n",
    "        for chunk in train_data_chunks:\n",
    "            # pre-process the data on-line\n",
    "            train_data, train_labels = process_train_data(chunk, cfg)\n",
    "            train(model, train_data, train_labels, val_data, val_labels, cfg)\n",
    "     \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    # TODO: Work on the train_valid_split\n",
    "    X_train, y_train, X_valid, y_valid = train_valid_split(train_data, train_labels) # Splitting the train data into train-valid data\n",
    "    \n",
    "    \n",
    "    # TODO: Work on the process_test_data\n",
    "    X_test = process_test_data(test_data) # Converting DataFrame to numpy array\n",
    "    \n",
    "    model = baselineLSTM(cfg) # Replace this with model = <your model name>(cfg)\n",
    "    if cfg['cuda']:\n",
    "        computing_device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        computing_device = torch.device(\"cpu\")\n",
    "    model.to(computing_device)\n",
    "    \n",
    "    train(model, X_train, y_train, X_valid, y_valid, cfg) # Train the model, we should perform the encoding per mini-batch basis\n",
    "    outputs = generate(model, X_test, cfg) # Generate the outputs for test data\n",
    "    \n",
    "    # TODO: Work on the save_to_file\n",
    "    save_to_file(outputs, out_fname) # Save the generated outputs to a file\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
